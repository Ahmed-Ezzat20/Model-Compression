{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install nni\nimport time\nfrom typing import Callable, Union, Union\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.optim import Optimizer, SGD\nfrom torch.utils.data import DataLoader\nfrom torch import Tensor\n\nfrom nni.common.types import SCHEDULER","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:11:49.917003Z","iopub.execute_input":"2025-01-09T18:11:49.917304Z","iopub.status.idle":"2025-01-09T18:12:14.619193Z","shell.execute_reply.started":"2025-01-09T18:11:49.917281Z","shell.execute_reply":"2025-01-09T18:12:14.618254Z"}},"outputs":[{"name":"stdout","text":"Collecting nni\n  Downloading nni-3.0-py3-none-manylinux1_x86_64.whl.metadata (19 kB)\nCollecting astor (from nni)\n  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from nni) (3.1.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from nni) (0.4.6)\nCollecting filelock<3.12 (from nni)\n  Downloading filelock-3.11.0-py3-none-any.whl.metadata (2.5 kB)\nCollecting json-tricks>=3.15.5 (from nni)\n  Downloading json_tricks-3.17.3-py2.py3-none-any.whl.metadata (16 kB)\nCollecting nvidia-ml-py (from nni)\n  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nni) (24.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nni) (2.1.4)\nRequirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from nni) (3.11.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from nni) (5.9.5)\nCollecting PythonWebHDFS (from nni)\n  Downloading PythonWebHDFS-0.2.3-py3-none-any.whl.metadata (717 bytes)\nRequirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from nni) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nni) (2.32.3)\nCollecting responses (from nni)\n  Downloading responses-0.25.3-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting schema (from nni)\n  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\nRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from nni) (1.2.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nni) (4.66.5)\nCollecting typeguard<4.1.3,>=3.0.0 (from nni)\n  Downloading typeguard-4.1.2-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from nni) (4.12.2)\nRequirement already satisfied: websockets>=10.1 in /usr/local/lib/python3.10/dist-packages (from nni) (14.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nni) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nni) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->nni) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->nni) (3.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->nni) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nni) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nni) (2024.1)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->nni) (0.2.13)\nCollecting simplejson (from PythonWebHDFS->nni)\n  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (2024.8.30)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->nni) (1.16.0)\nDownloading nni-3.0-py3-none-manylinux1_x86_64.whl (61.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading filelock-3.11.0-py3-none-any.whl (10.0 kB)\nDownloading json_tricks-3.17.3-py2.py3-none-any.whl (27 kB)\nDownloading typeguard-4.1.2-py3-none-any.whl (33 kB)\nDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nDownloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading PythonWebHDFS-0.2.3-py3-none-any.whl (10 kB)\nDownloading responses-0.25.3-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\nDownloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: schema, nvidia-ml-py, json-tricks, typeguard, simplejson, filelock, astor, responses, PythonWebHDFS, nni\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.3.0\n    Uninstalling typeguard-4.3.0:\n      Successfully uninstalled typeguard-4.3.0\n  Attempting uninstall: filelock\n    Found existing installation: filelock 3.16.1\n    Uninstalling filelock-3.16.1:\n      Successfully uninstalled filelock-3.16.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytensor 2.25.4 requires filelock>=3.15, but you have filelock 3.11.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed PythonWebHDFS-0.2.3 astor-0.8.1 filelock-3.11.0 json-tricks-3.17.3 nni-3.0 nvidia-ml-py-12.560.30 responses-0.25.3 schema-0.7.7 simplejson-3.19.3 typeguard-4.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Define the model","metadata":{}},{"cell_type":"code","source":"class CNN(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = torch.nn.Conv2d(1, 20, 5, 1)\n        self.conv2 = torch.nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = torch.nn.Linear(4 * 4 * 50, 500)\n        self.fc2 = torch.nn.Linear(500, 10)\n        self.relu1 = torch.nn.ReLU6()\n        self.relu2 = torch.nn.ReLU6()\n        self.relu3 = torch.nn.ReLU6()\n        self.max_pool1 = torch.nn.MaxPool2d(2, 2)\n        self.max_pool2 = torch.nn.MaxPool2d(2, 2)\n        self.batchnorm1 = torch.nn.BatchNorm2d(20)\n\n    def forward(self, x):\n        x = self.relu1(self.batchnorm1(self.conv1(x)))\n        x = self.max_pool1(x)\n        x = self.relu2(self.conv2(x))\n        x = self.max_pool2(x)\n        x = x.view(-1, 4 * 4 * 50)\n        x = self.relu3(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:12:14.620449Z","iopub.execute_input":"2025-01-09T18:12:14.621067Z","iopub.status.idle":"2025-01-09T18:12:14.627450Z","shell.execute_reply.started":"2025-01-09T18:12:14.621031Z","shell.execute_reply":"2025-01-09T18:12:14.626665Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Create training and evaluation dataloader","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\n\nMNIST(root='data/mnist', train=True, download=True)\nMNIST(root='data/mnist', train=False, download=True)\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\nmnist_train = MNIST(root='data/mnist', train=True, transform=transform)\ntrain_dataloader = DataLoader(mnist_train, batch_size=64)\nmnist_test = MNIST(root='data/mnist', train=False, transform=transform)\ntest_dataloader = DataLoader(mnist_test, batch_size=1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:12:14.628753Z","iopub.execute_input":"2025-01-09T18:12:14.629037Z","iopub.status.idle":"2025-01-09T18:12:15.512468Z","shell.execute_reply.started":"2025-01-09T18:12:14.629003Z","shell.execute_reply":"2025-01-09T18:12:15.511503Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Define training and evaluation functions","metadata":{}},{"cell_type":"code","source":"device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n\ndef training_step(batch, model) -> Tensor:\n    x, y = batch[0].to(device), batch[1].to(device)\n    logits = model(x)\n    loss: torch.Tensor = F.nll_loss(logits, y)\n    return loss\n\n\ndef training_model(model: torch.nn.Module, optimizer: Optimizer, training_step: Callable, scheduler: Union[SCHEDULER, None] = None,\n                   max_steps: Union[int, None] = None, max_epochs: Union[int, None] = None):\n    model.train()\n    max_epochs = max_epochs if max_epochs else 1 if max_steps is None else 100\n    current_steps = 0\n\n    # training\n    for epoch in range(max_epochs):\n        print(f'Epoch {epoch} start!')\n        for batch in train_dataloader:\n            optimizer.zero_grad()\n            loss = training_step(batch, model)\n            loss.backward()\n            optimizer.step()\n            current_steps += 1\n            if max_steps and current_steps == max_steps:\n                return\n        if scheduler is not None:\n            scheduler.step()\n\n\ndef evaluating_model(model: torch.nn.Module):\n    model.eval()\n    # testing\n    correct = 0\n    with torch.no_grad():\n        for x, y in test_dataloader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            preds = torch.argmax(logits, dim=1)\n            correct += preds.eq(y.view_as(preds)).sum().item()\n    return correct / len(mnist_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:12:15.513590Z","iopub.execute_input":"2025-01-09T18:12:15.513875Z","iopub.status.idle":"2025-01-09T18:12:15.564656Z","shell.execute_reply.started":"2025-01-09T18:12:15.513838Z","shell.execute_reply":"2025-01-09T18:12:15.564005Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Pre-train and evaluate the model on MNIST dataset","metadata":{}},{"cell_type":"code","source":"model = CNN().to(device)\noptimizer = SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n\nstart = time.time()\ntraining_model(model, optimizer, training_step, None, None, 5)\nprint(f'pure training 5 epochs: {time.time() - start}s')\nstart = time.time()\nacc = evaluating_model(model)\nprint(f'pure evaluating: {time.time() - start}s    Acc.: {acc}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:12:15.565531Z","iopub.execute_input":"2025-01-09T18:12:15.565790Z","iopub.status.idle":"2025-01-09T18:13:24.160740Z","shell.execute_reply.started":"2025-01-09T18:12:15.565764Z","shell.execute_reply":"2025-01-09T18:13:24.159803Z"}},"outputs":[{"name":"stdout","text":"Epoch 0 start!\nEpoch 1 start!\nEpoch 2 start!\nEpoch 3 start!\nEpoch 4 start!\npure training 5 epochs: 66.45247530937195s\npure evaluating: 1.918260097503662s    Acc.: 0.9907\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Quantizing Model","metadata":{}},{"cell_type":"code","source":"import nni\nfrom nni.compression.quantization import QATQuantizer\nfrom nni.compression.utils import TorchEvaluator\n\n\noptimizer = nni.trace(SGD)(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\nevaluator = TorchEvaluator(training_model, optimizer, training_step)  # type: ignore\n\nconfig_list = [{\n    'op_names': ['conv1', 'conv2', 'fc1', 'fc2'],\n    'target_names': ['_input_', 'weight', '_output_'],\n    'quant_dtype': 'int8',\n    'quant_scheme': 'affine',\n    'granularity': 'default',\n},{\n    'op_names': ['relu1', 'relu2', 'relu3'],\n    'target_names': ['_output_'],\n    'quant_dtype': 'int8',\n    'quant_scheme': 'affine',\n    'granularity': 'default',\n}]\n\nquantizer = QATQuantizer(model, config_list, evaluator, len(train_dataloader))\nreal_input = next(iter(train_dataloader))[0].to(device)\nquantizer.track_forward(real_input)\n\nstart = time.time()\n_, calibration_config = quantizer.compress(None, max_epochs=5)\nprint(f'pure training 5 epochs: {time.time() - start}s')\n\nprint(calibration_config)\nstart = time.time()\nacc = evaluating_model(model)\nprint(f'quantization evaluating: {time.time() - start}s    Acc.: {acc}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:13:24.161783Z","iopub.execute_input":"2025-01-09T18:13:24.162040Z","iopub.status.idle":"2025-01-09T18:15:28.766177Z","shell.execute_reply.started":"2025-01-09T18:13:24.162017Z","shell.execute_reply":"2025-01-09T18:15:28.765427Z"}},"outputs":[{"name":"stdout","text":"Epoch 0 start!\nEpoch 1 start!\nEpoch 2 start!\nEpoch 3 start!\nEpoch 4 start!\npure training 5 epochs: 120.5745861530304s\ndefaultdict(<class 'dict'>, {'conv2': {'weight': {'scale': tensor(0.0012), 'zero_point': tensor(-18.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.1775), 'tracked_min': tensor(-0.1334)}, '_input_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(5.9957), 'tracked_min': tensor(0.)}, '_output_0': {'scale': tensor(0.0913), 'zero_point': tensor(0.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(11.6309), 'tracked_min': tensor(-11.5534)}}, 'conv1': {'weight': {'scale': tensor(0.0024), 'zero_point': tensor(-1.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.3048), 'tracked_min': tensor(-0.3022)}, '_input_0': {'scale': tensor(0.0128), 'zero_point': tensor(-94.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(2.8215), 'tracked_min': tensor(-0.4242)}, '_output_0': {'scale': tensor(0.0264), 'zero_point': tensor(-6.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(3.5068), 'tracked_min': tensor(-3.2109)}}, 'fc1': {'weight': {'scale': tensor(0.0007), 'zero_point': tensor(-1.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.0870), 'tracked_min': tensor(-0.0857)}, '_input_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(6.), 'tracked_min': tensor(0.)}, '_output_0': {'scale': tensor(0.0633), 'zero_point': tensor(-3.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(8.2578), 'tracked_min': tensor(-7.8211)}}, 'fc2': {'weight': {'scale': tensor(0.0017), 'zero_point': tensor(-11.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.2378), 'tracked_min': tensor(-0.2005)}, '_input_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(6.), 'tracked_min': tensor(0.)}, '_output_0': {'scale': tensor(0.1534), 'zero_point': tensor(-36.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(25.0642), 'tracked_min': tensor(-13.9016)}}, 'relu1': {'_output_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(5.9962), 'tracked_min': tensor(0.)}}, 'relu3': {'_output_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(6.), 'tracked_min': tensor(0.)}}, 'relu2': {'_output_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(6.), 'tracked_min': tensor(0.)}}})\nquantization evaluating: 1.9869418144226074s    Acc.: 0.9911\n","output_type":"stream"}],"execution_count":9}]}
